{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fallen-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Activation\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "varied-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bronze-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "LOG_DIR = f\"{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fantastic-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  # random search passes this hyperparameter() object \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten()) \n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "under-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=1,  # how many model variations to test?\n",
    "    executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n",
    "    directory=LOG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "amazing-exception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 32s]\n",
      "val_accuracy: 0.8317000269889832\n",
      "\n",
      "Best val_accuracy So Far: 0.8317000269889832\n",
      "Total elapsed time: 00h 00m 32s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x=x_train,\n",
    "             y=y_train,\n",
    "             verbose=2, # just slapping this here bc jupyter notebook. The console out was getting messy.\n",
    "             epochs=1,\n",
    "             batch_size=64,\n",
    "             #callbacks=[tensorboard],  # if you have callbacks like tensorboard, they go here.\n",
    "             validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "comic-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(hp):  # random search passes this hyperparameter() object \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Conv2D(hp.Int('input_units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), (3, 3), input_shape=x_train.shape[1:]))\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for i in range(hp.Int('n_layers', 1, 4)):  # adding variation of layers.\n",
    "        model.add(Conv2D(hp.Int(f'conv_{i}_units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "worthy-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 03m 42s]\n",
      "val_accuracy: 0.862500011920929\n",
      "\n",
      "Best val_accuracy So Far: 0.862500011920929\n",
      "Total elapsed time: 00h 03m 42s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model2,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=1,  # how many model variations to test?\n",
    "    executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n",
    "    directory=LOG_DIR)\n",
    "\n",
    "tuner.search(x=x_train,\n",
    "             y=y_train,\n",
    "             verbose=2, # just slapping this here bc jupyter notebook. The console out was getting messy.\n",
    "             epochs=1,\n",
    "             batch_size=64,\n",
    "             #callbacks=[tensorboard],  # if you have callbacks like tensorboard, they go here.\n",
    "             validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "recognized-anatomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_units': 160,\n",
       " 'n_layers': 3,\n",
       " 'conv_0_units': 96,\n",
       " 'conv_1_units': 32,\n",
       " 'conv_2_units': 32}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aging-posting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 160)       1600      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26, 26, 160)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 160)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 96)        138336    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 11, 11, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 32)          27680     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                15690     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 192,554\n",
      "Trainable params: 192,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "tuner.get_best_models()[0].summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-alabama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
